{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your token and repo URL\n",
    "token = \"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\"\n",
    "!git clone https://{token}@github.com/puru-samal/thesis.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import yaml\n",
    "from data import DrumMIDIDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "from torchinfo import summary\n",
    "from models.IQAE import IQAE\n",
    "from trainers import IQAE_Trainer\n",
    "from utils import create_optimizer, create_scheduler\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting _configs/config_test.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile _configs/config_test.yaml\n",
    "\n",
    "name : \"Puru\"\n",
    "expt : \"Test\"\n",
    "\n",
    "###### Dataset -----------------------------------------------------------------\n",
    "data:\n",
    "    train_path: \"dataset/serialized/merged_ts=4-4_tr0.80-va0.10-te0.10_train.pkl\"\n",
    "    val_path: \"dataset/serialized/merged_ts=4-4_tr0.80-va0.10-te0.10_val.pkl\"\n",
    "    test_path: \"dataset/serialized/merged_ts=4-4_tr0.80-va0.10-te0.10_test.pkl\"\n",
    "    num_bars: 2\n",
    "    feature_type: \"fixed\"  # [fixed, flexible]\n",
    "    steps_per_quarter: 4\n",
    "    subset: 0.05            # Fraction of the dataset to load\n",
    "    num_workers: 0         # Number of workers for data loading\n",
    "    batch_size: 16         # Batch size\n",
    "\n",
    "###### Network Specs -------------------------------------------------------------\n",
    "model:\n",
    "    embed_dim: 32\n",
    "    encoder_depth: 1\n",
    "    encoder_heads: 1\n",
    "    decoder_depth: 1\n",
    "    decoder_heads: 1\n",
    "    num_buttons: 3\n",
    "\n",
    "###### Common Training Parameters ------------------------------------------------\n",
    "training:\n",
    "  config_file                 : \"_configs/config_test.yaml\"\n",
    "  use_wandb                   : False   # Toggle wandb logging\n",
    "  wandb_run_id                : \"none\" # \"none\" or \"run_id\"\n",
    "  resume                      : True   # Resume an existing run (run_id != 'none')\n",
    "  gradient_accumulation_steps : 1\n",
    "  wandb_project               : \"Set-Project-Name-Here\" # wandb project to log to\n",
    "\n",
    "###### Loss ----------------------------------------------------------------------\n",
    "loss: # Just good ol' CrossEntropy\n",
    "  label_smoothing: 0.0\n",
    "  ctc_weight: 0.2\n",
    "\n",
    "###### Optimizer -----------------------------------------------------------------\n",
    "optimizer:\n",
    "  name: \"adamw\" # Options: sgd, adam, adamw\n",
    "  lr: 0.0004    # Base learning rate\n",
    "\n",
    "  # Common parameters\n",
    "  weight_decay: 0.000001\n",
    "\n",
    "  # Parameter groups\n",
    "  # You can add more param groups as you want and set their learning rates and patterns\n",
    "  param_groups:\n",
    "    - name: self_attn\n",
    "      patterns: []  # Will match all parameters containing \"encoder\"\n",
    "      lr: 0.0002    # LR for self_attn\n",
    "      layer_decay:\n",
    "        enabled: False\n",
    "        decay_rate: 0.8\n",
    "\n",
    "    - name: ffn\n",
    "      patterns: []\n",
    "      lr: 0.0002  # LR for ffn\n",
    "      layer_decay:\n",
    "        enabled: False\n",
    "        decay_rate: 0.8\n",
    "\n",
    "  # Layer-wise learning rates\n",
    "  layer_decay:\n",
    "    enabled: False\n",
    "    decay_rate: 0.75\n",
    "\n",
    "  # SGD specific parameters\n",
    "  sgd:\n",
    "    momentum: 0.9\n",
    "    nesterov: True\n",
    "    dampening: 0\n",
    "\n",
    "  # Adam specific parameters\n",
    "  adam:\n",
    "    betas: [0.9, 0.999]\n",
    "    eps: 1.0e-8\n",
    "    amsgrad: False\n",
    "\n",
    "  # AdamW specific parameters\n",
    "  adamw:\n",
    "    betas: [0.9, 0.999]\n",
    "    eps: 1.0e-8\n",
    "    amsgrad: False\n",
    "\n",
    "###### Scheduler -----------------------------------------------------------------\n",
    "scheduler:\n",
    "  name: \"cosine\"  # Options: reduce_lr, cosine, cosine_warm\n",
    "\n",
    "  # ReduceLROnPlateau specific parameters\n",
    "  reduce_lr:\n",
    "    mode: \"min\"  # Options: min, max\n",
    "    factor: 0.1  # Factor to reduce learning rate by\n",
    "    patience: 10  # Number of epochs with no improvement after which LR will be reduced\n",
    "    threshold: 0.0001  # Threshold for measuring the new optimum\n",
    "    threshold_mode: \"rel\"  # Options: rel, abs\n",
    "    cooldown: 0  # Number of epochs to wait before resuming normal operation\n",
    "    min_lr: 0.0000001  # Minimum learning rate\n",
    "    eps: 1e-8  # Minimal decay applied to lr\n",
    "\n",
    "  # CosineAnnealingLR specific parameters\n",
    "  cosine:\n",
    "    T_max: 15  # Maximum number of iterations\n",
    "    eta_min: 0.0000001  # Minimum learning rate\n",
    "    last_epoch: -1\n",
    "\n",
    "  # CosineAnnealingWarmRestarts specific parameters\n",
    "  cosine_warm:\n",
    "    T_0: 10    # Number of iterations for the first restart\n",
    "    T_mult: 10 # Factor increasing T_i after each restart\n",
    "    eta_min: 0.0000001  # Minimum learning rate\n",
    "    last_epoch: -1\n",
    "\n",
    "  # Warmup parameters (can be used with any scheduler)\n",
    "  warmup:\n",
    "    enabled: True\n",
    "    type: \"exponential\"  # Options: linear, exponential\n",
    "    epochs: 5\n",
    "    start_factor: 0.1\n",
    "    end_factor: 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('_configs/config_test.yaml', 'r') as file:\n",
    "    config = yaml.safe_load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets / Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset from: dataset/serialized/merged_ts=4-4_tr0.80-va0.10-te0.10_train.pkl...\n",
      "Processing 6578 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accumulating:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6578/6578 [00:01<00:00, 5399.37sample/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples due to errors.\n",
      "Loaded and processed 6578 samples.\n",
      "\n",
      "Number of negative samples in fixed grid: 6778010\n",
      "Number of positive samples in fixed grid: 398096\n",
      "pos_weight: 17.02606964111328\n",
      "Loading dataset from: dataset/serialized/merged_ts=4-4_tr0.80-va0.10-te0.10_val.pkl...\n",
      "Processing 813 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accumulating:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 813/813 [00:00<00:00, 5500.94sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples due to errors.\n",
      "Loaded and processed 813 samples.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative samples in fixed grid: 806458\n",
      "Number of positive samples in fixed grid: 45316\n",
      "pos_weight: 17.79631996154785\n",
      "Loading dataset from: dataset/serialized/merged_ts=4-4_tr0.80-va0.10-te0.10_test.pkl...\n",
      "Processing 812 samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Accumulating:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 812/812 [00:00<00:00, 5198.33sample/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 samples due to errors.\n",
      "Loaded and processed 812 samples.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative samples in fixed grid: 871512\n",
      "Number of positive samples in fixed grid: 50314\n",
      "pos_weight: 17.321460723876953\n",
      "Grid shape: torch.Size([16, 33, 9, 3])\n",
      "Samples shape: 16\n"
     ]
    }
   ],
   "source": [
    "## Load Datasets\n",
    "train_dataset = DrumMIDIDataset(\n",
    "    path     = config[\"data\"][\"train_path\"],\n",
    "    num_bars = config[\"data\"][\"num_bars\"],\n",
    "    feature_type = config[\"data\"][\"feature_type\"],\n",
    "    steps_per_quarter = config[\"data\"][\"steps_per_quarter\"],\n",
    "    subset   = config[\"data\"][\"subset\"]\n",
    ")\n",
    "\n",
    "val_dataset = DrumMIDIDataset(\n",
    "    path     = config[\"data\"][\"val_path\"],\n",
    "    num_bars = config[\"data\"][\"num_bars\"],\n",
    "    feature_type = config[\"data\"][\"feature_type\"],\n",
    "    steps_per_quarter = config[\"data\"][\"steps_per_quarter\"],\n",
    "    subset   = config[\"data\"][\"subset\"]\n",
    ")\n",
    "\n",
    "test_dataset = DrumMIDIDataset(\n",
    "    path     = config[\"data\"][\"test_path\"],\n",
    "    num_bars = config[\"data\"][\"num_bars\"],\n",
    "    feature_type = config[\"data\"][\"feature_type\"],\n",
    "    steps_per_quarter = config[\"data\"][\"steps_per_quarter\"],\n",
    "    subset   = config[\"data\"][\"subset\"]\n",
    ")\n",
    "\n",
    "## Create DataLoaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size = config[\"data\"][\"batch_size\"],\n",
    "    num_workers = config[\"data\"][\"num_workers\"],\n",
    "    shuffle = True,\n",
    "    collate_fn = lambda batch: train_dataset.collate_fn(batch, train_dataset),\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size = config[\"data\"][\"batch_size\"],\n",
    "    num_workers = config[\"data\"][\"num_workers\"],\n",
    "    shuffle = True,\n",
    "    collate_fn = lambda batch: val_dataset.collate_fn(batch, val_dataset),\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = config[\"data\"][\"batch_size\"],\n",
    "    num_workers = config[\"data\"][\"num_workers\"],\n",
    "    shuffle = True,\n",
    "    collate_fn = lambda batch: test_dataset.collate_fn(batch, test_dataset),\n",
    "    pin_memory = True\n",
    ")\n",
    "\n",
    "## Test a sample\n",
    "for batch in train_loader:\n",
    "    print(f\"Grid shape: {batch['grid'].shape}\")\n",
    "    print(f\"Samples shape: {len(batch['samples'])}\")\n",
    "    grid = batch['grid']\n",
    "    random_idx = np.random.randint(len(batch['samples']))\n",
    "    sample = batch['samples'][random_idx]\n",
    "    sample.feature.play()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length: 33\n"
     ]
    }
   ],
   "source": [
    "NUM_QUARTERS_PER_BAR = 4 # 4/4 time signature\n",
    "MAX_LENGTH = config[\"data\"][\"num_bars\"] * NUM_QUARTERS_PER_BAR * config[\"data\"][\"steps_per_quarter\"] + 1\n",
    "print(f\"Max length: {MAX_LENGTH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=========================================================================================================\n",
       "Layer (type:depth-idx)                                  Output Shape              Param #\n",
       "=========================================================================================================\n",
       "IQAE                                                    [16, 33, 9]               27\n",
       "â”œâ”€DrumAxialTransformer: 1-1                             [16, 33, 9, 32]           --\n",
       "â”‚    â””â”€Conv2d: 2-1                                      [16, 32, 33, 9]           128\n",
       "â”‚    â””â”€AxialPositionalEmbedding: 2-2                    [16, 32, 33, 9]           1,344\n",
       "â”‚    â””â”€Sequential: 2-3                                  [16, 32, 33, 9]           --\n",
       "â”‚    â”‚    â””â”€ModuleList: 3-1                             --                        156,288\n",
       "â”œâ”€AdaptiveAvgPool2d: 1-2                                [16, 33, 3, 3]            --\n",
       "â”œâ”€Linear: 1-3                                           [16, 33, 2]               20\n",
       "â”œâ”€IntegerQuantizer: 1-4                                 [16, 33]                  --\n",
       "â”œâ”€Linear: 1-5                                           [16, 33, 32]              896\n",
       "â”œâ”€PositionalEncoding: 1-6                               [16, 33, 32]              --\n",
       "â”œâ”€Linear: 1-7                                           [16, 33, 32]              320\n",
       "â”œâ”€PositionalEncoding: 1-8                               [16, 33, 32]              --\n",
       "â”œâ”€TransformerDecoder: 1-9                               [16, 33, 32]              --\n",
       "â”‚    â””â”€ModuleList: 2-4                                  --                        --\n",
       "â”‚    â”‚    â””â”€TransformerDecoderLayer: 3-2                [16, 33, 32]              141,792\n",
       "â”‚    â””â”€LayerNorm: 2-5                                   [16, 33, 32]              64\n",
       "â”œâ”€Linear: 1-10                                          [16, 33, 27]              891\n",
       "=========================================================================================================\n",
       "Total params: 301,770\n",
       "Trainable params: 301,770\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.MEGABYTES): 707.83\n",
       "=========================================================================================================\n",
       "Input size (MB): 0.06\n",
       "Forward/backward pass size (MB): 38.92\n",
       "Params size (MB): 1.17\n",
       "Estimated Total Size (MB): 40.15\n",
       "========================================================================================================="
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_config = config[\"model\"]\n",
    "model_config.update(\n",
    "    T=MAX_LENGTH,\n",
    "    E=grid.shape[2],\n",
    "    M=grid.shape[3]\n",
    ")\n",
    "model = IQAE(**model_config)\n",
    "summary(model, input_data = grid, device = \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "\n",
      "ðŸ”§ Configuring Optimizer:\n",
      "â”œâ”€â”€ Type: ADAMW\n",
      "â”œâ”€â”€ Base LR: 0.0004\n",
      "â”œâ”€â”€ Weight Decay: 1e-06\n",
      "â”œâ”€â”€ Parameter Groups:\n",
      "â”‚   â”œâ”€â”€ Group: self_attn\n",
      "â”‚   â”‚   â”œâ”€â”€ LR: 0.0002\n",
      "â”‚   â”‚   â””â”€â”€ Patterns: []\n",
      "â”‚   â”œâ”€â”€ Group: ffn\n",
      "â”‚   â”‚   â”œâ”€â”€ LR: 0.0002\n",
      "â”‚   â”‚   â””â”€â”€ Patterns: []\n",
      "â”‚   â””â”€â”€ Default Group (unmatched parameters)\n",
      "â””â”€â”€ AdamW Specific:\n",
      "    â”œâ”€â”€ Betas: [0.9, 0.999]\n",
      "    â”œâ”€â”€ Epsilon: 1e-08\n",
      "    â””â”€â”€ AMSGrad: False\n",
      "\n",
      "ðŸ“ˆ Configuring Learning Rate Scheduler:\n",
      "â”œâ”€â”€ Type: COSINE\n",
      "â”œâ”€â”€ Cosine Annealing Settings:\n",
      "â”‚   â”œâ”€â”€ T_max: 15 epochs (6180 steps)\n",
      "â”‚   â””â”€â”€ Min LR: 1e-07\n",
      "â”œâ”€â”€ Warmup Settings:\n",
      "â”‚   â”œâ”€â”€ Duration: 5 epochs (2060 steps)\n",
      "â”‚   â”œâ”€â”€ Start Factor: 0.1\n",
      "â”‚   â””â”€â”€ End Factor: 1.0\n"
     ]
    }
   ],
   "source": [
    "trainer = IQAE_Trainer(\n",
    "    model = model,\n",
    "    config = config,\n",
    "    run_name = config[\"expt\"],\n",
    "    config_file = config['training']['config_file'],\n",
    "    device = device\n",
    ")\n",
    "\n",
    "trainer.set_optimizer(\n",
    "    create_optimizer(\n",
    "        model=model,\n",
    "        opt_config=config['optimizer']\n",
    "    )\n",
    ")\n",
    "\n",
    "trainer.set_scheduler(\n",
    "    create_scheduler(\n",
    "        optimizer=trainer.optimizer,\n",
    "        scheduler_config=config['scheduler'],\n",
    "        train_loader=train_loader,\n",
    "        gradient_accumulation_steps=config['training']['gradient_accumulation_steps']\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                    \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length: 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Metrics (Epoch 0):\n",
      "â”œâ”€â”€ TRAIN:\n",
      "â”‚   â”œâ”€â”€ hit_bce: 1.3998\n",
      "â”‚   â”œâ”€â”€ joint_loss: 1.6342\n",
      "â”‚   â”œâ”€â”€ margin_loss: 0.0000\n",
      "â”‚   â”œâ”€â”€ offset_mse: 0.0388\n",
      "â”‚   â”œâ”€â”€ temporal_loss: 0.0000\n",
      "â”‚   â””â”€â”€ velocity_mse: 0.1955\n",
      "â””â”€â”€ VAL:\n",
      "    â”œâ”€â”€ hit_acc: 0.7382\n",
      "    â”œâ”€â”€ hit_f1: 0.3996\n",
      "    â”œâ”€â”€ hit_ppv: 0.2708\n",
      "    â”œâ”€â”€ hit_tpr: 0.8475\n",
      "    â”œâ”€â”€ offset_mse: 0.0043\n",
      "    â””â”€â”€ velocity_mse: 0.1315\n",
      "â””â”€â”€ TRAINING:\n",
      "    â””â”€â”€ learning_rate: 0.000112\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, val_loader, epochs=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
